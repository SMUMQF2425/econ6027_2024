ellipse_coords <- cbind(
axis_lengths[1] * cos(theta),
axis_lengths[2] * sin(theta)
)
# Rotate the ellipse by the specified angle
rotation_matrix <- matrix(c(cos(angle), -sin(angle), sin(angle), cos(angle)), ncol = 2)
rotated_coords <- ellipse_coords %*% rotation_matrix
# Translate the ellipse to the mean center
ellipse_coords <- sweep(rotated_coords, 2, mean_centre, "+")
return(ellipse_coords)
}
# Generate points for the ellipse
ellipse_points <- generate_ellipse_points(ellipse_quakes$mean_center, ellipse_quakes$axis_lengths, ellipse_quakes$angle)
# Load the required libraries
library(sp)
library(spData)
library(sf)
library(tmap)
library(leaflet)
library(spatstat)
library(car)
# Question 1
# a) Load the "cycle_hire" dataset
data("cycle_hire", package = "spData")
# b) Compute a standard deviational ellipse
# Convert the 'cycle_hire' sf object to a ppp object
cycle_hire_coords <- st_coordinates(cycle_hire)
# Compute the standard deviational ellipse
ellipse_cycle_hire <- dataEllipse(cycle_hire_coords[,1], cycle_hire_coords[,2],
levels = 0.95, draw = FALSE)
# Save the ellipse points to a .txt file
write.table(ellipse_cycle_hire, file = "ellipse_cycle_hire.txt", row.names = FALSE)
# To visualize it on a plot (not interactive map)
plot(cycle_hire_coords, main = "Cycle Hire Points and Standard Deviational Ellipse")
lines(ellipse_cycle_hire, col = "red", lwd = 2)
# Convert ellipse points to sf polygon
ellipse_polygon <- st_polygon(list(as.matrix(ellipse_cycle_hire)))
# Convert the polygon to an sf object
ellipse_sf <- st_sfc(ellipse_polygon, crs = st_crs(cycle_hire))
# Plot the points and the ellipse on a leaflet map
leaflet() %>%
addProviderTiles("OpenStreetMap") %>%
addCircleMarkers(data = cycle_hire, lng = ~st_coordinates(cycle_hire)[,1], lat = ~st_coordinates(cycle_hire)[,2], color = "blue") %>%
addPolygons(data = ellipse_sf, color = "red", weight = 2)
# c) Plot hire points and the ellipse on an interactive map using leaflet
# Create a new sf object by combining the coordinates with the original data
cycle_hire_sf <- cbind(cycle_hire, cycle_hire_coords)
# Convert ellipse points (from car::dataEllipse) to sf polygon
ellipse_polygon <- st_polygon(list(as.matrix(ellipse_cycle_hire)))
# Convert the polygon to an sf object
ellipse_sf <- st_sfc(ellipse_polygon, crs = st_crs(cycle_hire))
# Plot the points and the ellipse on a leaflet map
leaflet() %>%
addProviderTiles("OpenStreetMap") %>%
addCircleMarkers(data = cycle_hire_sf, lng = ~X, lat = ~Y, color = "blue", radius = 3) %>%
addPolygons(data = ellipse_sf, color = "red", weight = 2)
# Question 2
# a) Load the "quakes" dataset and assign spatial coordinates
data("quakes")
quakes_sf <- st_as_sf(quakes, coords = c("long", "lat"), crs = 4326)
# Generate the head of the dataset
head(quakes_sf)
# b) Prepare two interactive maps of magnitude and depth using tmap
tmap_mode("view")
tm_shape(quakes_sf) +
tm_dots(col = "mag", palette = "-Spectral", title = "Magnitude") +
tm_basemap("OpenStreetMap")
tm_shape(quakes_sf) +
tm_dots(col = "depth", palette = "Blues", title = "Depth") +
tm_basemap("OpenStreetMap")
# c) Compute the mean centre and standard deviational ellipse with magnitude as weights
# Function to compute standard deviational ellipse
compute_sde <- function(coords, weights = NULL) {
# Mean centre
mean_centre <- colMeans(coords)
# If weights are provided, calculate weighted mean centre
if (!is.null(weights)) {
mean_centre <- colSums(coords * weights) / sum(weights)
}
# Centre the coordinates
centred_coords <- sweep(coords, 2, mean_centre, "-")
# Compute covariance matrix (weighted if weights are provided)
if (!is.null(weights)) {
cov_matrix <- cov.wt(centred_coords, wt = weights)$cov
} else {
cov_matrix <- cov(centred_coords)
}
# Eigenvalue decomposition of covariance matrix
eig <- eigen(cov_matrix)
# Get lengths of ellipse axes (sqrt of eigenvalues)
axis_lengths <- sqrt(eig$values)
# Get rotation angle of ellipse (from eigenvectors)
angle <- atan2(eig$vectors[2, 1], eig$vectors[1, 1])
list(mean_center = mean_centre, axis_lengths = axis_lengths, angle = angle)
}
# Compute standard deviational ellipse for quakes using magnitude as weights
coords <- st_coordinates(quakes_sf)
weights <- quakes$mag
ellipse_quakes <- compute_sde(coords, weights)
# Print the mean centre, axis lengths, and angle of the ellipse
print(ellipse_quakes)
# Optionally, create a visualisation of the ellipse
# Define a function to generate ellipse points for visualisation
generate_ellipse_points <- function(mean_centre, axis_lengths, angle, n_points = 100) {
theta <- seq(0, 2 * pi, length.out = n_points)
# Parametric equation for an ellipse
ellipse_coords <- cbind(
axis_lengths[1] * cos(theta),
axis_lengths[2] * sin(theta)
)
# Rotate the ellipse by the specified angle
rotation_matrix <- matrix(c(cos(angle), -sin(angle), sin(angle), cos(angle)), ncol = 2)
rotated_coords <- ellipse_coords %*% rotation_matrix
# Translate the ellipse to the mean centre
ellipse_coords <- sweep(rotated_coords, 2, mean_centre, "+")
# Ensure the ellipse is closed by adding the first point as the last point
ellipse_coords <- rbind(ellipse_coords, ellipse_coords[1, ])
return(ellipse_coords)
}
# Generate the ellipse points
ellipse_points <- generate_ellipse_points(ellipse_quakes$mean_center, ellipse_quakes$axis_lengths, ellipse_quakes$angle)
# Convert the ellipse points to an sf polygon
ellipse_polygon <- st_polygon(list(ellipse_points))
# Convert the polygon to an sf object
ellipse_sf <- st_sfc(ellipse_polygon, crs = st_crs(quakes_sf))
# d) Plot the output on a static map
tm_shape(quakes_sf) +
tm_dots(col = "mag", title = "Earthquake Magnitude") +
tm_shape(ellipse_sf) +
tm_borders(col = "red", lwd = 2) +
tm_layout(title = "Standard Deviational Ellipse for Quakes")
# Question 3
# 1. Load the "sg_house.csv" dataset and the Singapore shapefile, and combine them
sg_house <- read.csv("sg_house.csv")
# Load the required libraries
library(sp)
library(spData)
library(sf)
library(tmap)
library(leaflet)
library(spatstat)
library(car)
# Question 1
# a) Load the "cycle_hire" dataset
data("cycle_hire", package = "spData")
cycle_hire
# b) Compute a standard deviational ellipse
# Convert the 'cycle_hire' sf object to a ppp object
cycle_hire_coords <- st_coordinates(cycle_hire)
# Compute the standard deviational ellipse
ellipse_cycle_hire <- dataEllipse(cycle_hire_coords[,1], cycle_hire_coords[,2],
levels = 0.95, draw = FALSE)
# Save the ellipse points to a .txt file
write.table(ellipse_cycle_hire, file = "ellipse_cycle_hire.txt", row.names = FALSE)
# To visualize it on a plot (not interactive map)
plot(cycle_hire_coords, main = "Cycle Hire Points and Standard Deviational Ellipse")
lines(ellipse_cycle_hire, col = "red", lwd = 2)
# Convert ellipse points to sf polygon
ellipse_polygon <- st_polygon(list(as.matrix(ellipse_cycle_hire)))
# Convert the polygon to an sf object
ellipse_sf <- st_sfc(ellipse_polygon, crs = st_crs(cycle_hire))
# Plot the points and the ellipse on a leaflet map
leaflet() %>%
addProviderTiles("OpenStreetMap") %>%
addCircleMarkers(data = cycle_hire, lng = ~st_coordinates(cycle_hire)[,1], lat = ~st_coordinates(cycle_hire)[,2], color = "blue") %>%
addPolygons(data = ellipse_sf, color = "red", weight = 2)
# c) Plot hire points and the ellipse on an interactive map using leaflet
# Create a new sf object by combining the coordinates with the original data
cycle_hire_sf <- cbind(cycle_hire, cycle_hire_coords)
# Convert ellipse points (from car::dataEllipse) to sf polygon
ellipse_polygon <- st_polygon(list(as.matrix(ellipse_cycle_hire)))
# Convert the polygon to an sf object
ellipse_sf <- st_sfc(ellipse_polygon, crs = st_crs(cycle_hire))
# Plot the points and the ellipse on a leaflet map
leaflet() %>%
addProviderTiles("OpenStreetMap") %>%
addCircleMarkers(data = cycle_hire_sf, lng = ~X, lat = ~Y, color = "blue", radius = 3) %>%
addPolygons(data = ellipse_sf, color = "red", weight = 2)
# Question 2
# a) Load the "quakes" dataset and assign spatial coordinates
data("quakes")
quakes_sf <- st_as_sf(quakes, coords = c("long", "lat"), crs = 4326)
# Generate the head of the dataset
head(quakes_sf)
# b) Prepare two interactive maps of magnitude and depth using tmap
tmap_mode("view")
tm_shape(quakes_sf) +
tm_dots(col = "mag", palette = "-Spectral", title = "Magnitude") +
tm_basemap("OpenStreetMap")
tm_shape(quakes_sf) +
tm_dots(col = "depth", palette = "Blues", title = "Depth") +
tm_basemap("OpenStreetMap")
# c) Compute the mean centre and standard deviational ellipse with magnitude as weights
# Function to compute standard deviational ellipse
compute_sde <- function(coords, weights = NULL) {
# Mean centre
mean_centre <- colMeans(coords)
# If weights are provided, calculate weighted mean centre
if (!is.null(weights)) {
mean_centre <- colSums(coords * weights) / sum(weights)
}
# Centre the coordinates
centred_coords <- sweep(coords, 2, mean_centre, "-")
# Compute covariance matrix (weighted if weights are provided)
if (!is.null(weights)) {
cov_matrix <- cov.wt(centred_coords, wt = weights)$cov
} else {
cov_matrix <- cov(centred_coords)
}
# Eigenvalue decomposition of covariance matrix
eig <- eigen(cov_matrix)
# Get lengths of ellipse axes (sqrt of eigenvalues)
axis_lengths <- sqrt(eig$values)
# Get rotation angle of ellipse (from eigenvectors)
angle <- atan2(eig$vectors[2, 1], eig$vectors[1, 1])
list(mean_center = mean_centre, axis_lengths = axis_lengths, angle = angle)
}
# Compute standard deviational ellipse for quakes using magnitude as weights
coords <- st_coordinates(quakes_sf)
weights <- quakes$mag
ellipse_quakes <- compute_sde(coords, weights)
# Print the mean centre, axis lengths, and angle of the ellipse
print(ellipse_quakes)
# Optionally, create a visualisation of the ellipse
# Define a function to generate ellipse points for visualisation
generate_ellipse_points <- function(mean_centre, axis_lengths, angle, n_points = 100) {
theta <- seq(0, 2 * pi, length.out = n_points)
# Parametric equation for an ellipse
ellipse_coords <- cbind(
axis_lengths[1] * cos(theta),
axis_lengths[2] * sin(theta)
)
# Rotate the ellipse by the specified angle
rotation_matrix <- matrix(c(cos(angle), -sin(angle), sin(angle), cos(angle)), ncol = 2)
rotated_coords <- ellipse_coords %*% rotation_matrix
# Translate the ellipse to the mean centre
ellipse_coords <- sweep(rotated_coords, 2, mean_centre, "+")
# Ensure the ellipse is closed by adding the first point as the last point
ellipse_coords <- rbind(ellipse_coords, ellipse_coords[1, ])
return(ellipse_coords)
}
# Generate the ellipse points
ellipse_points <- generate_ellipse_points(ellipse_quakes$mean_center, ellipse_quakes$axis_lengths, ellipse_quakes$angle)
# Convert the ellipse points to an sf polygon
ellipse_polygon <- st_polygon(list(ellipse_points))
# Convert the polygon to an sf object
ellipse_sf <- st_sfc(ellipse_polygon, crs = st_crs(quakes_sf))
ellipse_sf
# d) Plot the output on a static map
tm_shape(quakes_sf) +
tm_dots(col = "mag", title = "Earthquake Magnitude") +
tm_shape(ellipse_sf) +
tm_borders(col = "red", lwd = 2) +
tm_layout(title = "Standard Deviational Ellipse for Quakes")
# Question 3
# 1. Load the "sg_house.csv" dataset and the Singapore shapefile, and combine them
sg_house <- read.csv("sg_house.csv")
# Load libraries
library(sf)            # For handling GeoJSON and spatial data
library(spatstat)      # For spatial point pattern analysis
library(tmap)          # For map visualisation
library(ggmap)         # Geocoding service using Google Maps
library(ggplot2)       # For general plotting
library(dplyr)         # For data wrangling
library(spdep)         # For spatial dependencies and neighbourhood analysis
# 1. Data Preparation
# Load the resale flat prices dataset
resale_data <- read.csv("ResaleflatpricesbasedonregistrationdatefromJan2017onwards.csv")
gc()
# Load libraries
library(sf)            # For handling GeoJSON and spatial data
library(spatstat)      # For spatial point pattern analysis
library(tmap)          # For map visualisation
library(ggplot2)       # For general plotting
library(tidyr)         # For tidying data
library(dplyr)         # For data wrangling
library(spdep)         # For spatial dependencies and neighbourhood analysis
library(tidygeocoder)  # For geocoding
# 1. Data Preparation
# Load the resale flat prices dataset
resale_data <- read.csv("ResaleflatpricesbasedonregistrationdatefromJan2017onwards.csv")
install.packages("devtools")
devtools::install_github("IRkernel/IRkernel")
IRkernel::installspec()
install.packages(c( "tidyverse", "gt", "rmarkdown", "gtsummary", "palmerpenguins"))
library(spdep, quietly = T); library(spatialreg, quietly = T)
data(used.cars, package="spData")
ls()
head(used.cars)
class(used.cars)
class(usa48.nb)
cars_ols = lm(formula = price.1960 ~ tax.charges, data = used.cars)
summary(cars_ols)
lmtest::bptest(cars_ols)
tseries::jarque.bera.test(cars_ols$residuals)
# normtest::jb.norm.test(cars_ols$residuals)
normtest::jb.norm.test(cars_ols$residuals)
install.packages("normtest")
cars_wlist = nb2listw(usa48.nb, style="W")
lm.morantest(cars_ols, cars_wlist)
moran.test(used.cars$price.1960, cars_wlist)
?lm.morantest
cars_sar = spautolm(formula = price.1960 ~ 1, data=used.cars, listw=cars_wlist)
summary(cars_sar)
cars_slm = lagsarlm(formula = price.1960 ~ tax.charges, data=used.cars, listw=cars_wlist)
summary(cars_slm)
cars_sem = errorsarlm(formula = price.1960 ~ tax.charges, data=used.cars, listw=cars_wlist)
summary(cars_sem)
?stsls
?lagsarlm
cars_sarar = sacsarlm(formula = price.1960 ~ tax.charges, data=used.cars, listw=cars_wlist)
summary(cars_sarar)
AIC(cars_ols); AIC(cars_sar); AIC(cars_sem); AIC(cars_slm); AIC(cars_sarar)
?lagsarlm
lm.LMtests(cars_ols, listw=cars_wlist, test="all")
?RStests
??RStests
??RStests
LR1.Sarlm(cars_slm) # reject H0
LR1.Sarlm(cars_sarar) # reject H0
LR.Sarlm(cars_sem,cars_sarar) # SEM vs SARAR --> reject H0
LR.Sarlm(cars_slm,cars_sarar) # SLM vs SARAR --> do not reject H0
LR.Sarlm(cars_sar,cars_slm) # SAR vs SLM --> do not reject H0
?optimize
?errorsarlm
?GMerrorsar
?sacsarlm
?gstsls
?lm.LMtests
?LR.Sarlm
library(gstat)
library(dismo); library(sf); library(tmap)
install.packages("raster")
install.packages("raster")
library(gstat)
library(dismo); library(sf); library(tmap)
library(raster)
knitr::spin(hair = "mi_covid.R", knit = FALSE)
setwd("~/Downloads/EC627 Spatial Econometrics & Data Analysis")
knitr::spin(hair = "mi_covid.R", knit = FALSE)
knitr::spin(hair = "sg_air.R", knit = FALSE)
knitr::spin(hair = "plymouth.R", knit = FALSE)
knitr::spin(hair = "plymouth.R", knit = FALSE)
library(rmarkdown)
render(mi_covid.Rmd)
render("mi_covid.Rmd"")
render("mi_covid.Rmd")
render("mi_covid.Rmd")
setwd("~/Downloads/EC627 Spatial Econometrics & Data Analysis/mock final")
render("mi_covid.Rmd")
setwd("~/Downloads/EC627 Spatial Econometrics & Data Analysis/mock final")
setwd("~/Downloads/EC627 Spatial Econometrics & Data Analysis/mock final/data/Q1")
render("mi_covid.Rmd")
render("mi_covid.Rmd")
render("mi_covid.Rmd")
render("mi_covid.Rmd")
render("mi_covid.Rmd")
render("mi_covid.Rmd")
render("mi_covid.Rmd")
setwd("~/Downloads/EC627 Spatial Econometrics & Data Analysis/mock final/data/Q2")
render("sg_air.Rmd")
render("sg_air.Rmd")
render("plymouth.Rmd")
setwd("~/Downloads/EC627 Spatial Econometrics & Data Analysis/mock final/data/Q3")
render("plymouth.Rmd")
setwd("~/Downloads/EC627 Spatial Econometrics & Data Analysis/mock final 2/Q1a")
(wards_err = read.gal("wards_err.gal"))
wards_err = read.gal("wards_err.gal")
(wards_err = read.gal("wards_err.GAL"))
library(spdep); library(spatialreg)
(wards_err = read.gal("wards_err.GAL"))
(wards.nb = read.gal("wards.GAL"))
# Spatial weights
(wards.nb = read.gal("wards.GAL"))
(wards.wlist = nb2listw(wards.nb))
(wards.wlistB = nb2listw(wards.nb, style="B"))
# Sheffield burglary data
load("burglary.Rdata")
head(burglary)
burglary$BURG_1000 = (burglary$BURG/burglary$HH)*1000
head(burglary)
moran.test(burglary$BURG_1000, listw=wards.wlist)
-1/(nrow(burglary)-1)
localm = localmoran(burglary$BURG_1000, listw=wards.wlist)
head(localm)
sum(localm[.1])/nrow(burglary) # Global Moran's I as the sum of Local Moran's I
moran.plot(burglary$BURG_1000, wards.wlist, main="Moran scatterplot") # Moran's plot
sum(localm[,1])/nrow(burglary) # Global Moran's I as the sum of Local Moran's I
moran.plot(burglary$BURG_1000, wards.wlist, main="Moran scatterplot") # Moran's plot
burglary$TDI_IO = as.factor(burglary$TDI < 0)
head(burglary)
table(burglary$TDI_IO)
joincount.multi(burglary$TDI_IO, listw=wards.wlist)
library(terra)
raster_filepath = system.file("raster/srtm.tif", package = "spDataLarge") # identify the file
zion = rast(raster_filepath) # rasterise the tif
# raster_filepath = system.file("raster/srtm.tif", package = "spDataLarge") # identify the file
zion = rast(system.file("raster/srtm.tif", package = "spDataLarge")) # rasterise the tif
raster_filepath = system.file("raster/srtm.tif", package = "spDataLarge") # identify the file
zion = rast(raster_filepath) # rasterise the tif
?rast
raster_filepath = system.file("raster/srtm.tif", package = "spDataLarge")
zion = rast(raster_filepath)
setwd("~/Downloads/EC627 Spatial Econometrics & Data Analysis")
raster_filepath = system.file("raster/srtm.tif", package = "spDataLarge") # identify the file
zion = rast(raster_filepath)
setwd("~/Downloads/EC627 Spatial Econometrics & Data Analysis")
raster_filepath = system.file("raster/srtm.tif", package = "spDataLarge") # identify the file
zion = rast(raster_filepath)
zion = rast(raster_filepath)
zion = rast(system.file("raster/srtm.tif", package = "spDataLarge"))
zion = rast("raster/srtm.tif", package = "spDataLarge")
zion = rast("raster/srtm.tif")
install.packages("spDataLarge")
install.packages("spDataLarge", repos = "https://geocompr.r-universe.dev")
raster_filepath = system.file("raster/srtm.tif", package = "spDataLarge") # identify the file
zion = rast(raster_filepath) # rasterise the tif
class(zion) # Notice the new class “Spatraster”.
zion # shows the raster header
# Basic maps
plot(zion, main="Zion National Park")
library(rmarkdown)
render("09a.Rmd")
setwd("~/Downloads/EC627 Spatial Econometrics & Data Analysis/mock final/Q2")
render("sg_air.Rmd")
#####################
# IDW INTERPOLATION #
#####################
(sg_grid = sg %>% st_sample(size=10000, type="regular") %>% st_set_crs(CRS))
# idp = 1
(idw1 = idw(US_AQI~1, locations=sg_air, newdata=sg_grid, idp = 1))
library(rmarkdown)
render("sg_air.Rmd")
setwd("~/Downloads/EC627 Spatial Econometrics & Data Analysis/mock final 2/Q1a")
render("sheffield.Rmd")
render("sheffield.Rmd")
setwd("~/Downloads/EC627 Spatial Econometrics & Data Analysis/mock final 2/Q1b")
render("italy.Rmd")
setwd("~/Downloads/EC627 Spatial Econometrics & Data Analysis/mock final 2/Q2")
render("topo.Rmd")
setwd("~/Downloads/EC627 Spatial Econometrics & Data Analysis/mock final 2/Q3")
render("ruspini.Rmd")
install.packages("maptools")
library(spatstat); library(sf); library(tmap); library(sp)
# load data
load("ruspini.Rdata")
head(ruspini)
(ruspini.sf = st_as_sf(ruspini, coords = c("x", "y")))
plot(ruspini.sf, main="ruspini points")
# to ppp
(ruspini.ppp = as.ppp(st_geometry(ruspini.sf)))
plot(ruspini.ppp)
##########################
# QUADRAT COUNT ANALYSIS #
##########################
qc = quadratcount(ruspini.ppp,nx=10, ny=15)
plot(qc)
(quad.test = quadrat.test(ruspini.ppp, nx=10, ny=15))
# Reject the null of CSR at 5% level of significance.
# plots
qc = data.frame(qc)
qc.table = data.frame(table(qc$Freq, exclude=NULL))
qc.table[,1] = as.numeric(levels(qc.table[,1]))
qc.table$xf = qc.table[,1]*qc.table[,2]
sums = colSums(qc.table[,-1])
lambda = sums[2]/sums[1]
qc.table$O_pr = qc.table[,2]/sums[1]
qc.table$E_pr = dpois(qc.table[,1], lambda=lambda)
plot(c(0,6),c(0,.8), type="n",
xlab="Number of incidents per Subquadrat (Red=Observed, Blue=Expected)",
ylab="Frequency of Occurances", main="Quadrat counts: Observed vs Expected")
points(qc.table$Var1, qc.table$E_pr, col="Blue", type="l", lwd=2)
points(qc.table$Var1, qc.table$O_pr, col="Red", type="l", lwd=2)
# the point pattern does not follow an HPP due to the difference at counts 0, 1 & 2.
############################
# KKERNEL DENSITY ESTIMATE #
############################
kde1 = density(ruspini.ppp, sigma=bw.scott(ruspini.ppp))
kde2 = density(ruspini.ppp, sigma=bw.diggle(ruspini.ppp))
kde3 = density(ruspini.ppp, sigma=bw.CvL(ruspini.ppp))
kde4 = density(ruspini.ppp, sigma=bw.ppl(ruspini.ppp))
# Sigma values
bw.scott(ruspini.ppp)
bw.diggle(ruspini.ppp)
bw.CvL(ruspini.ppp)
bw.ppl(ruspini.ppp)
plot(kde1, main="Kernel denstiy using Scott's rule")
plot(kde2, main="Kernel denstiy using Diggle method")
plot(kde3, main="Kernel denstiy using CvL method")
plot(kde4, main="Kernel denstiy using ppl method")
# Four visible clusters.
# The northern cluster is the most intense.
#######################################
# NEAREST NEIGHBOUR DISTANCE ANALYSIS #
#######################################
ruspini.nnd = nndist(ruspini.ppp, k=1)
summary(ruspini.nnd)
hist(ruspini.nnd)
clarkevans(ruspini.ppp, correction="Donnelly")
clarkevans.test(ruspini.ppp, correction="Donnelly", alternative="clustered")
# Conclusion: there seem to be significant clustering in this data.
#######################
# K-FUNCTION ANALYSIS #
#######################
kf = envelope(ruspini.ppp, Kest, correction="best", alternative="greater")
gf = envelope(ruspini.ppp, Gest, correction="best", alternative="greater")
par(mfrow=c(1,2))
plot(kf, main="K-Function")
plot(gf, main="G-Function")
par(mfrow=c(1,1))
# Significant clustering present
render("ruspini.Rmd")
