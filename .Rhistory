ellipse_coords <- sweep(rotated_coords, 2, mean_centre, "+")
return(ellipse_coords)
}
# Generate points for the ellipse
ellipse_points <- generate_ellipse_points(ellipse_quakes$mean_center, ellipse_quakes$axis_lengths, ellipse_quakes$angle)
# Load the required libraries
library(sp)
library(spData)
library(sf)
library(tmap)
library(leaflet)
library(spatstat)
library(car)
# Question 1
# a) Load the "cycle_hire" dataset
data("cycle_hire", package = "spData")
# b) Compute a standard deviational ellipse
# Convert the 'cycle_hire' sf object to a ppp object
cycle_hire_coords <- st_coordinates(cycle_hire)
# Compute the standard deviational ellipse
ellipse_cycle_hire <- dataEllipse(cycle_hire_coords[,1], cycle_hire_coords[,2],
levels = 0.95, draw = FALSE)
# Save the ellipse points to a .txt file
write.table(ellipse_cycle_hire, file = "ellipse_cycle_hire.txt", row.names = FALSE)
# To visualize it on a plot (not interactive map)
plot(cycle_hire_coords, main = "Cycle Hire Points and Standard Deviational Ellipse")
lines(ellipse_cycle_hire, col = "red", lwd = 2)
# Convert ellipse points to sf polygon
ellipse_polygon <- st_polygon(list(as.matrix(ellipse_cycle_hire)))
# Convert the polygon to an sf object
ellipse_sf <- st_sfc(ellipse_polygon, crs = st_crs(cycle_hire))
# Plot the points and the ellipse on a leaflet map
leaflet() %>%
addProviderTiles("OpenStreetMap") %>%
addCircleMarkers(data = cycle_hire, lng = ~st_coordinates(cycle_hire)[,1], lat = ~st_coordinates(cycle_hire)[,2], color = "blue") %>%
addPolygons(data = ellipse_sf, color = "red", weight = 2)
# c) Plot hire points and the ellipse on an interactive map using leaflet
# Create a new sf object by combining the coordinates with the original data
cycle_hire_sf <- cbind(cycle_hire, cycle_hire_coords)
# Convert ellipse points (from car::dataEllipse) to sf polygon
ellipse_polygon <- st_polygon(list(as.matrix(ellipse_cycle_hire)))
# Convert the polygon to an sf object
ellipse_sf <- st_sfc(ellipse_polygon, crs = st_crs(cycle_hire))
# Plot the points and the ellipse on a leaflet map
leaflet() %>%
addProviderTiles("OpenStreetMap") %>%
addCircleMarkers(data = cycle_hire_sf, lng = ~X, lat = ~Y, color = "blue", radius = 3) %>%
addPolygons(data = ellipse_sf, color = "red", weight = 2)
# Question 2
# a) Load the "quakes" dataset and assign spatial coordinates
data("quakes")
quakes_sf <- st_as_sf(quakes, coords = c("long", "lat"), crs = 4326)
# Generate the head of the dataset
head(quakes_sf)
# b) Prepare two interactive maps of magnitude and depth using tmap
tmap_mode("view")
tm_shape(quakes_sf) +
tm_dots(col = "mag", palette = "-Spectral", title = "Magnitude") +
tm_basemap("OpenStreetMap")
tm_shape(quakes_sf) +
tm_dots(col = "depth", palette = "Blues", title = "Depth") +
tm_basemap("OpenStreetMap")
# c) Compute the mean centre and standard deviational ellipse with magnitude as weights
# Function to compute standard deviational ellipse
compute_sde <- function(coords, weights = NULL) {
# Mean centre
mean_centre <- colMeans(coords)
# If weights are provided, calculate weighted mean centre
if (!is.null(weights)) {
mean_centre <- colSums(coords * weights) / sum(weights)
}
# Centre the coordinates
centred_coords <- sweep(coords, 2, mean_centre, "-")
# Compute covariance matrix (weighted if weights are provided)
if (!is.null(weights)) {
cov_matrix <- cov.wt(centred_coords, wt = weights)$cov
} else {
cov_matrix <- cov(centred_coords)
}
# Eigenvalue decomposition of covariance matrix
eig <- eigen(cov_matrix)
# Get lengths of ellipse axes (sqrt of eigenvalues)
axis_lengths <- sqrt(eig$values)
# Get rotation angle of ellipse (from eigenvectors)
angle <- atan2(eig$vectors[2, 1], eig$vectors[1, 1])
list(mean_center = mean_centre, axis_lengths = axis_lengths, angle = angle)
}
# Compute standard deviational ellipse for quakes using magnitude as weights
coords <- st_coordinates(quakes_sf)
weights <- quakes$mag
ellipse_quakes <- compute_sde(coords, weights)
# Print the mean centre, axis lengths, and angle of the ellipse
print(ellipse_quakes)
# Optionally, create a visualisation of the ellipse
# Define a function to generate ellipse points for visualisation
generate_ellipse_points <- function(mean_centre, axis_lengths, angle, n_points = 100) {
theta <- seq(0, 2 * pi, length.out = n_points)
# Parametric equation for an ellipse
ellipse_coords <- cbind(
axis_lengths[1] * cos(theta),
axis_lengths[2] * sin(theta)
)
# Rotate the ellipse by the specified angle
rotation_matrix <- matrix(c(cos(angle), -sin(angle), sin(angle), cos(angle)), ncol = 2)
rotated_coords <- ellipse_coords %*% rotation_matrix
# Translate the ellipse to the mean centre
ellipse_coords <- sweep(rotated_coords, 2, mean_centre, "+")
# Ensure the ellipse is closed by adding the first point as the last point
ellipse_coords <- rbind(ellipse_coords, ellipse_coords[1, ])
return(ellipse_coords)
}
# Generate the ellipse points
ellipse_points <- generate_ellipse_points(ellipse_quakes$mean_center, ellipse_quakes$axis_lengths, ellipse_quakes$angle)
# Convert the ellipse points to an sf polygon
ellipse_polygon <- st_polygon(list(ellipse_points))
# Convert the polygon to an sf object
ellipse_sf <- st_sfc(ellipse_polygon, crs = st_crs(quakes_sf))
# d) Plot the output on a static map
tm_shape(quakes_sf) +
tm_dots(col = "mag", title = "Earthquake Magnitude") +
tm_shape(ellipse_sf) +
tm_borders(col = "red", lwd = 2) +
tm_layout(title = "Standard Deviational Ellipse for Quakes")
# Question 3
# 1. Load the "sg_house.csv" dataset and the Singapore shapefile, and combine them
sg_house <- read.csv("sg_house.csv")
# Load the required libraries
library(sp)
library(spData)
library(sf)
library(tmap)
library(leaflet)
library(spatstat)
library(car)
# Question 1
# a) Load the "cycle_hire" dataset
data("cycle_hire", package = "spData")
cycle_hire
# b) Compute a standard deviational ellipse
# Convert the 'cycle_hire' sf object to a ppp object
cycle_hire_coords <- st_coordinates(cycle_hire)
# Compute the standard deviational ellipse
ellipse_cycle_hire <- dataEllipse(cycle_hire_coords[,1], cycle_hire_coords[,2],
levels = 0.95, draw = FALSE)
# Save the ellipse points to a .txt file
write.table(ellipse_cycle_hire, file = "ellipse_cycle_hire.txt", row.names = FALSE)
# To visualize it on a plot (not interactive map)
plot(cycle_hire_coords, main = "Cycle Hire Points and Standard Deviational Ellipse")
lines(ellipse_cycle_hire, col = "red", lwd = 2)
# Convert ellipse points to sf polygon
ellipse_polygon <- st_polygon(list(as.matrix(ellipse_cycle_hire)))
# Convert the polygon to an sf object
ellipse_sf <- st_sfc(ellipse_polygon, crs = st_crs(cycle_hire))
# Plot the points and the ellipse on a leaflet map
leaflet() %>%
addProviderTiles("OpenStreetMap") %>%
addCircleMarkers(data = cycle_hire, lng = ~st_coordinates(cycle_hire)[,1], lat = ~st_coordinates(cycle_hire)[,2], color = "blue") %>%
addPolygons(data = ellipse_sf, color = "red", weight = 2)
# c) Plot hire points and the ellipse on an interactive map using leaflet
# Create a new sf object by combining the coordinates with the original data
cycle_hire_sf <- cbind(cycle_hire, cycle_hire_coords)
# Convert ellipse points (from car::dataEllipse) to sf polygon
ellipse_polygon <- st_polygon(list(as.matrix(ellipse_cycle_hire)))
# Convert the polygon to an sf object
ellipse_sf <- st_sfc(ellipse_polygon, crs = st_crs(cycle_hire))
# Plot the points and the ellipse on a leaflet map
leaflet() %>%
addProviderTiles("OpenStreetMap") %>%
addCircleMarkers(data = cycle_hire_sf, lng = ~X, lat = ~Y, color = "blue", radius = 3) %>%
addPolygons(data = ellipse_sf, color = "red", weight = 2)
# Question 2
# a) Load the "quakes" dataset and assign spatial coordinates
data("quakes")
quakes_sf <- st_as_sf(quakes, coords = c("long", "lat"), crs = 4326)
# Generate the head of the dataset
head(quakes_sf)
# b) Prepare two interactive maps of magnitude and depth using tmap
tmap_mode("view")
tm_shape(quakes_sf) +
tm_dots(col = "mag", palette = "-Spectral", title = "Magnitude") +
tm_basemap("OpenStreetMap")
tm_shape(quakes_sf) +
tm_dots(col = "depth", palette = "Blues", title = "Depth") +
tm_basemap("OpenStreetMap")
# c) Compute the mean centre and standard deviational ellipse with magnitude as weights
# Function to compute standard deviational ellipse
compute_sde <- function(coords, weights = NULL) {
# Mean centre
mean_centre <- colMeans(coords)
# If weights are provided, calculate weighted mean centre
if (!is.null(weights)) {
mean_centre <- colSums(coords * weights) / sum(weights)
}
# Centre the coordinates
centred_coords <- sweep(coords, 2, mean_centre, "-")
# Compute covariance matrix (weighted if weights are provided)
if (!is.null(weights)) {
cov_matrix <- cov.wt(centred_coords, wt = weights)$cov
} else {
cov_matrix <- cov(centred_coords)
}
# Eigenvalue decomposition of covariance matrix
eig <- eigen(cov_matrix)
# Get lengths of ellipse axes (sqrt of eigenvalues)
axis_lengths <- sqrt(eig$values)
# Get rotation angle of ellipse (from eigenvectors)
angle <- atan2(eig$vectors[2, 1], eig$vectors[1, 1])
list(mean_center = mean_centre, axis_lengths = axis_lengths, angle = angle)
}
# Compute standard deviational ellipse for quakes using magnitude as weights
coords <- st_coordinates(quakes_sf)
weights <- quakes$mag
ellipse_quakes <- compute_sde(coords, weights)
# Print the mean centre, axis lengths, and angle of the ellipse
print(ellipse_quakes)
# Optionally, create a visualisation of the ellipse
# Define a function to generate ellipse points for visualisation
generate_ellipse_points <- function(mean_centre, axis_lengths, angle, n_points = 100) {
theta <- seq(0, 2 * pi, length.out = n_points)
# Parametric equation for an ellipse
ellipse_coords <- cbind(
axis_lengths[1] * cos(theta),
axis_lengths[2] * sin(theta)
)
# Rotate the ellipse by the specified angle
rotation_matrix <- matrix(c(cos(angle), -sin(angle), sin(angle), cos(angle)), ncol = 2)
rotated_coords <- ellipse_coords %*% rotation_matrix
# Translate the ellipse to the mean centre
ellipse_coords <- sweep(rotated_coords, 2, mean_centre, "+")
# Ensure the ellipse is closed by adding the first point as the last point
ellipse_coords <- rbind(ellipse_coords, ellipse_coords[1, ])
return(ellipse_coords)
}
# Generate the ellipse points
ellipse_points <- generate_ellipse_points(ellipse_quakes$mean_center, ellipse_quakes$axis_lengths, ellipse_quakes$angle)
# Convert the ellipse points to an sf polygon
ellipse_polygon <- st_polygon(list(ellipse_points))
# Convert the polygon to an sf object
ellipse_sf <- st_sfc(ellipse_polygon, crs = st_crs(quakes_sf))
ellipse_sf
# d) Plot the output on a static map
tm_shape(quakes_sf) +
tm_dots(col = "mag", title = "Earthquake Magnitude") +
tm_shape(ellipse_sf) +
tm_borders(col = "red", lwd = 2) +
tm_layout(title = "Standard Deviational Ellipse for Quakes")
# Question 3
# 1. Load the "sg_house.csv" dataset and the Singapore shapefile, and combine them
sg_house <- read.csv("sg_house.csv")
# Load libraries
library(sf)            # For handling GeoJSON and spatial data
library(spatstat)      # For spatial point pattern analysis
library(tmap)          # For map visualisation
library(ggmap)         # Geocoding service using Google Maps
library(ggplot2)       # For general plotting
library(dplyr)         # For data wrangling
library(spdep)         # For spatial dependencies and neighbourhood analysis
# 1. Data Preparation
# Load the resale flat prices dataset
resale_data <- read.csv("ResaleflatpricesbasedonregistrationdatefromJan2017onwards.csv")
gc()
# Load libraries
library(sf)            # For handling GeoJSON and spatial data
library(spatstat)      # For spatial point pattern analysis
library(tmap)          # For map visualisation
library(ggplot2)       # For general plotting
library(tidyr)         # For tidying data
library(dplyr)         # For data wrangling
library(spdep)         # For spatial dependencies and neighbourhood analysis
library(tidygeocoder)  # For geocoding
# 1. Data Preparation
# Load the resale flat prices dataset
resale_data <- read.csv("ResaleflatpricesbasedonregistrationdatefromJan2017onwards.csv")
install.packages("devtools")
devtools::install_github("IRkernel/IRkernel")
IRkernel::installspec()
install.packages(c( "tidyverse", "gt", "rmarkdown", "gtsummary", "palmerpenguins"))
library(spdep, quietly = T); library(spatialreg, quietly = T)
data(used.cars, package="spData")
ls()
head(used.cars)
class(used.cars)
class(usa48.nb)
cars_ols = lm(formula = price.1960 ~ tax.charges, data = used.cars)
summary(cars_ols)
lmtest::bptest(cars_ols)
tseries::jarque.bera.test(cars_ols$residuals)
# normtest::jb.norm.test(cars_ols$residuals)
normtest::jb.norm.test(cars_ols$residuals)
install.packages("normtest")
cars_wlist = nb2listw(usa48.nb, style="W")
lm.morantest(cars_ols, cars_wlist)
moran.test(used.cars$price.1960, cars_wlist)
?lm.morantest
cars_sar = spautolm(formula = price.1960 ~ 1, data=used.cars, listw=cars_wlist)
summary(cars_sar)
cars_slm = lagsarlm(formula = price.1960 ~ tax.charges, data=used.cars, listw=cars_wlist)
summary(cars_slm)
cars_sem = errorsarlm(formula = price.1960 ~ tax.charges, data=used.cars, listw=cars_wlist)
summary(cars_sem)
?stsls
?lagsarlm
cars_sarar = sacsarlm(formula = price.1960 ~ tax.charges, data=used.cars, listw=cars_wlist)
summary(cars_sarar)
AIC(cars_ols); AIC(cars_sar); AIC(cars_sem); AIC(cars_slm); AIC(cars_sarar)
?lagsarlm
lm.LMtests(cars_ols, listw=cars_wlist, test="all")
?RStests
??RStests
??RStests
LR1.Sarlm(cars_slm) # reject H0
LR1.Sarlm(cars_sarar) # reject H0
LR.Sarlm(cars_sem,cars_sarar) # SEM vs SARAR --> reject H0
LR.Sarlm(cars_slm,cars_sarar) # SLM vs SARAR --> do not reject H0
LR.Sarlm(cars_sar,cars_slm) # SAR vs SLM --> do not reject H0
?optimize
?errorsarlm
?GMerrorsar
?sacsarlm
?gstsls
?lm.LMtests
?LR.Sarlm
library(gstat)
library(dismo); library(sf); library(tmap)
install.packages("raster")
install.packages("raster")
library(gstat)
library(dismo); library(sf); library(tmap)
library(raster)
setwd("~/Downloads/EC627 Spatial Econometrics & Data Analysis")
library(rmarkdown)
render("ECON6027 Assignment 2 (Chan Ric).Rmd")
render("ECON6027 Assignment 2 (Chan Ric).Rmd")
render("ECON6027 Assignment 2 (Chan Ric).Rmd")
render("Updated ECON6027 Assignment 2.Rmd")
render("Updated ECON6027 Assignment 2.Rmd")
render("Updated ECON6027 Assignment 2.Rmd")
render("Updated ECON6027 Assignment 2.Rmd")
render("Updated ECON6027 Assignment 2.Rmd")
library(gstat); library(sf); library(tmap); library(automap)
data(fulmar); fulmar99 = fulmar[fulmar$year==1999, ]
(fulmar99 = st_as_sf(fulmar99, coords=c("x","y"), crs=32631))
evgm = variogram(fulmar~1, data=fulmar99) # automatic bandwidth selection
# evgm = variogram(fulmar~1, data=fulmar99, boundaries=seq(0,260000,l=53))
View(evgm)
# evgm = variogram(fulmar~1, data=fulmar99) # automatic bandwidth selection
evgm = variogram(fulmar~1, data=fulmar99, boundaries=seq(0,260000,l=53))
View(evgm)
show.vgms()
vgm()
plot(evgm) # initial plot
show.vgms()
vgm()
plot(evgm)
evgm = variogram(fulmar~1, data=fulmar99) # automatic bandwidth selection
# evgm = variogram(fulmar~1, data=fulmar99, boundaries=seq(0,260000,l=53))
show.vgms()
vgm()
plot(evgm) # initial plot
?variogram
?vgms
??vgms
?sill
??sill
?vgm
?psill
?autofitVariogram
?krige
(fvgm = fit.variogram(evgm, vgm(psill=12, model="Exp", range=100000)))
plot(evgm, model=fvgm)
(fvgm = fit.variogram(evgm, vgm(psill=10, model="Exp", range=100000, nugget=2)))
plot(evgm, model=fvgm, main="model=exponential")
(fvgm = fit.variogram(evgm, vgm(psill=10, model="Gau", range=100000, nugget=2)))
plot(evgm, model=fvgm, main="model=Gaussian")
fulmar99.sp = as(fulmar99, "Spatial") # automap currently accepts only projected sp objects.
(autovgm = autofitVariogram(fulmar~1, fulmar99.sp))
plot(autovgm)
class(autovgm)
data(ncp.grid) # a set of unsampled points to reconstruct the surface
head(ncp.grid) # in practice you need to generate this using a random sample function
(ncp.gridsf = st_as_sf(ncp.grid, coords=c("x","y"), crs=32631))
(krig.est = krige(fulmar~1, fulmar99, newdata=ncp.gridsf, model=fvgm))
summary(krig.est)
View(krig.est)
OK_pred_map = tm_shape(krig.est) +
tm_dots(col="var1.pred", palette="YlGnBu", shape=15, size = 0.2,
breaks=c(-Inf,2,4,6,8,10,12,14,Inf), title="Fulmar density estimation, OK")
OK_var_map = tm_shape(krig.est) +
tm_dots(col="var1.var", palette="Blues", shape=15, size = 0.2,
title="Variance of OK estimate")
tmap_arrange(OK_pred_map, OK_var_map)
lm(fulmar~1, fulmar99)
mean(fulmar99$fulmar)
skrig.est = krige(fulmar~1, fulmar99, newdata=ncp.gridsf, beta=mean(fulmar99$fulmar), model=fvgm)
summary(skrig.est) # negative estimates present!
SK_pred_map = tm_shape(skrig.est) +
tm_dots(col="var1.pred", palette="YlGnBu", shape=15, size = 0.2,
breaks=c(-Inf,2,4,6,8,10,12,14,Inf), title="Fulmar density estimation, SK")
SK_var_map = tm_shape(skrig.est) +
tm_dots(col="var1.var", palette="Blues", shape=15, size = 0.2,
title="Variance of SK estimate")
tmap_arrange(SK_pred_map, SK_var_map)
tmap_arrange(OK_pred_map, SK_pred_map)
?AIC
?BIC
?SBC
?dismo
?voronoi
#############################
# OZONE LAYER INTERPOLATION #
#############################
library(gstat); library(sf); library(tmap)
# Load data
ozone_sf = st_read("ca_ozone_pts.shp")
CA_sf = st_read("ca_outline.shp")
isTRUE(all.equal(st_crs(ozone_sf), st_crs(CA_sf)))
st_crs(ozone_sf)$proj; st_crs(CA_sf)$proj
# The two CRSs are aligned, good to go!
st_is_valid(CA_sf); table(st_is_valid(ozone_sf)) # geometries are valid
# 1. NEAREST NEIGHBOUR INTERPOLATION
ozone_sp = as(ozone_sf,"Spatial")
voro_sp = dismo::voronoi(ozone_sp, ext=st_bbox(CA_sf))
# Mask the Voronoi Tesselation using the CA polygon
(voro_sf = voro_sp %>% st_as_sf(crs=st_crs(ozone_sf)) %>% st_intersection(CA_sf))
# plot
(voro_plot = tm_shape(voro_sf) +
tm_polygons(col="OZONE", title="O3 density, ppm", palette="YlGnBu") +
tm_layout(main.title='O3 NNI estimate'))
# There seem to be positive spatial autocorrelation in the Ozone layer!
# 2. IDW INTERPOLATION
# Create a grid of 100000 unsampled points (you may adjust this number)
(ca_grid = st_sample(CA_sf, size=100000, type="regular"))
(ozone_idw = idw(formula=OZONE~1, locations=ozone_sf, newdata=ca_grid, idp = 2))
# Alternativelyâ€¦
# (ozone_idwk = krige(formula=OZONE~1, locations=ozone_sf, newdata=ca_grid)) # variogram not specified
# isTRUE(all.equal(ozone_idw$var1.pred, ozone_idwk$var1.pred))
# plot
(idw_plot = tm_shape(ozone_idw) +
tm_dots(col="var1.pred", title="O3 density, ppm", palette="YlGnBu", size=0.02, shape=15) +
tm_layout(main.title="O3 IDW estimate"))
# If the execution is too slow, try the following:
# - Reduce the number of unsampled points
# - The resulting loss of resolution can be compensated by increasing the dot size.
# 3. KRIGING
# Fit the variogram
(autovgm = automap::autofitVariogram(OZONE~1, ozone_sp)) # check autofit first
# Pick "Stein" model
svgm = variogram(OZONE~1, ozone_sf) # empirical variogram
options(scipen = 999)
plot(svgm, main="Empirical semi-variogram") # make initial guesses here or use autofit estimates
(fvgm = fit.variogram(svgm, vgm(psill=0.0004, model="Ste", range=200000, nugget=0.0001), warn.if.neg=T))
plot(svgm, model=fvgm, main="Fitted semi-variogram, Stein's model") # trial and error other parametric models here.
# ordinary kriging
ozone_ok = krige(formula=OZONE~1, locations=ozone_sf, newdata=ca_grid, model=fvgm)
summary(ozone_ok) # no negative densities, no problem!
# plot
# In the chunk below we create small squares to represent the predicted value.
ok_plot = tm_shape(ozone_ok) +
tm_dots(col="var1.pred", title="O3 density, ppm", palette="YlGnBu", shape=15, size=0.05, breaks=seq(0.04,0.18,0.02)) +
tm_layout(main.title="O3 OK estimate")
varok_plot = tm_shape(ozone_ok) +
tm_dots(col="var1.var", title="Prediction Variance", palette="Reds", shape=15, size=0.05) +
tm_shape(ozone_sf) +
tm_dots() +
tm_layout(main.title="Variance of the OK estimate")
tmap_arrange(ok_plot, varok_plot)
# ESTIMATE COMPARISON
tmap_arrange(ok_plot, idw_plot, voro_plot)
# Notice how the OK estimate is the closest to NNI estimate when compared to the IDW estimate.
# IDW estimate over-estimates the ozone layer, in particular, over the Eastern region.
tmap_arrange(ok_plot, idw_plot, voro_plot)
?nugger
?nugget
??nugget
setwd("~/Downloads/EC627 Spatial Econometrics & Data Analysis/Assignment 1")
knitr::spin(hair = "homework1_solutions.R", knit = FALSE)
rmarkdown::render("homework1_solutions.Rmd")
rmarkdown::render("homework1_solutions.Rmd")
sg_house = read.table(pipe("pbpaste"), sep="\t", header=T)
# or > sg_house = read.table(pipe("pbpaste"), sep="\t", header=T) %>% as_tibble()
# for windows use: sg_house = read.table(file="clipboard", sep="\t", header=T) %>% as_tibble()
class(sg_house)
# setwd("C:/Users/sfliu/Dropbox/MSc/Lessons/1 Introduction")
sg_PA = st_read("MP14_PLNG_AREA_WEB_PL.shp")
table(st_is_valid(sg_PA)) # 8 false entries
# It is always a good idea to check the validity of the object before proceeding.
# If there are FALSE entries, use st_make_valid to validate the object.
sg_PA = st_make_valid(sg_PA); table(st_is_valid(sg_PA))
# next time directly the run the following command.
# sg_PA = st_read("MP14_PLNG_AREA_NO_SEA_PL.shp") %>% st_make_valid()
sg_house_sf = inner_join(sg_house, sg_PA)
?inner_join
View(sg_house)
View(sg_PA)
View(sg_house)
rmarkdown::render("homework1_solutions.Rmd")
rmarkdown::render("homework1_solutions.Rmd")
setwd("~/Downloads/EC627 Spatial Econometrics & Data Analysis")
rmarkdown::render("homework2_sols.Rmd")
rmarkdown::render("homework1_solutions.Rmd")
rmarkdown::render("homework2_sols.Rmd")
crime_map = tm_shape(columbus) + tm_polygons(col="CRIME")
hoval_map = tm_shape(columbus) + tm_polygons(col="HOVAL", palette="Blues")
inc_map = tm_shape(columbus) + tm_polygons(col="INC", palette="Greens")
tmap_arrange(crime_map, hoval_map, inc_map)
rmarkdown::render("homework2_sols.Rmd")
crime_map = tm_shape(columbus) + tm_polygons(col="CRIME")
hoval_map = tm_shape(columbus) + tm_polygons(col="HOVAL", palette="Blues")
inc_map = tm_shape(columbus) + tm_polygons(col="INC", palette="Greens")
tmap_arrange(crime_map, hoval_map, inc_map)
class(columbus)
rmarkdown::render("homework2_sols.Rmd")
